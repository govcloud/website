+++
draft = false
title = "Open First Day"
description="Open First Day presentation given by Statistics Canada."
language = "en"
tags = [
    "statistics canada",
    "cncf",
    "open first"
]
date = "2018-03-22T13:10:52-05:00"
type = "slide"
+++

<!-- .slide: id="intro" data-transition="concave" -->

# Open First Day

[github.com/statcan](https://github.com/statcan) <i class="fa fa-area-chart"></i></li>

Note:

This is a fun presentation for me because I get to talk about some of the open source work being done at Statistics Canada.

But more then that I get to talk about a philosophy that has been working its way in to the department and what appears to soon be the broader government as a whole.

---

<!-- .slide: id="devs" data-transition="concave" -->

# Developers

> Modernizing app delivery for Canadians

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li>William Hearn</li>
<li>@sylus <i class="fa fa-github"></i></li>
</ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li>Laurent Goderre</li>
<li>@LaurentGoderre <i class="fa fa-github"></i></li>
</ul>
</div>

Note:

Will:

I'm an Open Source developer of I don't want to say how many years and am currently working as a cloud engineer for the cloud operations team at Statistics Canada.

In my past I have worn many hats but primarily some people may know me from the Drupal community a platform which incidentally powers both Statistics Canada and Open Data portal as well as many other departments across the GoC.

I've been very lucky throughout my life to have been a part of some amazing open source communities particularly because I have been able to grow so much as a developer and meet some amazing people throughout.

As a personal note I can't really describe how it feels when you get to interact with one of your heroes in a GitHub issue.

If you get one thing from me during this talk I hope that it is that I wholeheartedly believe that it is "All about the community".

Laurent Goderre:

ToDo: Add Laurent Introduction Text

---

<!-- .slide: id="stc" data-transition="concave" -->

# Statistics Canada

* Decade of Open Source
* Encourages Developers to Contribute
* Starting to be Open by Default
* Return on Investment

Note:

Statistics Canada has been increasing in its use of Open Source technologies over the past few years and is poised to make bigger changes over the next several which I am very excited about.

Some of the more interesting things about this department is that at least in my experience it encourages Developers to contribute back to the community and has even permitted teams to develop completely in the open.

This might seem counter-intuitive at first but it brings with it a distinct set of benefits.

___

<!-- .slide: id="stc-use" data-transition="concave" -->

# Use of Open Source

* Angular / React.JS / Vue.js
* Drupal
* Solr
* Docker / Kubernetes

Note:

## Use of Open Source

I'm aware of quite a few teams leveraging frontend toolkits such as `Angular` / `React.JS` / `Vue.js` performing progressive enhancement on a variety of our web applications.

* Angular.js leveraged for our upcoming search pages
* React.JS used for our Cannabis Portal
* Vue.js for generating SAS Code to the front-end user

Close to my heart is a stellar WCMS team and matainers that have been using `Drupal` for the past 5+ years and all of whom develop (for the most part) in the open.

We also have a search team that uses `Apache Solr` for much of our search pages and product data pages.

* ELK

Really exciting to me is the amount of teams we have that are moving toward microservices by containerizing their applications.

* C#, .NET
* JS
* PHP

Finally we are taking quite a thorough look at Kubernetes which makes me pretty happy most days.

___

<!-- .slide: id="stc-contributions" data-transition="concave" -->

# Contributions

* Bootstrap / WET-BOEW Framework
* Drupal
* Docker / Kubernetes
* Data Visualizations
* CNCF Meet-up

Note:

Interestingly as once you start using Open Source as a agency you realize in order to maximize your benefits you often need to contribute back.

The following are a list of examples I am at least aware of:

### `Bootstrap` and the `WET-BOEW` jQuery Framework.

### Drupal

Developed a `Drupal WxT` platform that has been shared and leveraged by many other government departments even provincial ones.

* Numerous Patches against Drupal Core / Contributed modules

Played a significant role in the development of the Open Data / Open Government initiative which saw improvements being made to both `CKAN` and `Drupal` upstream.

* Public Service Excellence Awards
* Open Data won UK Award 2018

### Docker

* Improvements to Official Container images (Drupal, Node)
* Sharing our approach to Containerization (Linux, Windows) with other departments

### Kubernetes

* Improvements and additions to Official Kubernetes Helm Charts
* Sharing our approach to Kubernetes (Linux, Windows) with other departments

### Data Visualizations

* Data visualizations for public use
* Leverages customized improvements to d3.js

### CNCF Meetup

* Work with CDS hosting Monthly Cloud Native Meetups

Personally I have been encouraged by my department as it is seen as a net benefit to contribute back to the Open Source community.

> This might be a useful point to mention here that the agency actively seeks out Open Source developer talent.

___

<!-- .slide: id="stc-roi" data-transition="concave" -->

# RoI

* Code is of higher quality
* Focus on security and abstraction
* Attract developer talent
* Operational efficiency

Note:

I just wanted to quickly mention that we realized early on there is a lot of benefit to leveraging Open Source and it brings with it a significant return on investment.

For instance when you develop in the open:

* Your code is of higher quality and usually goes through some sort of linting, building through CI (circle, travis, etc)
* More focus is placed on security and abstraction
* Ability for others to peer review and improve your code (Personally this has been really valuable to me)
* Attract developer talent (ToDo: Write out personal anectode)

When you leverage high quality Open Source projects **with thriving communities**:

* Innate ability to improve the software
* Gain Exceptional support from passionate people
* Operational efficiency with speed of execution

I think Statistics Canada is heading in the right direction but there is still a lot more work to do so expect to see the following from us!

* Open Source our Cannabis Platform and make available for P.R. (ToDo: Ask if we can do this)
* More consolidation of our disparate open source repositories work under official repository (ToDo: List examples)
* Showcasing of our new API (jsonAPI) which Laurent will soon be talking about
* A few examples of our internal golang applications being created (ToDo: Bug Chris M)

---

<!-- .slide: id="dataviz-intro" data-transition="concave" -->

# DataViz at StatsCan

* Open Source and Format(s)

Note:

___

<!-- .slide: id="dataviz-why-os" data-transition="concave" -->

# Why Open Source?

> It's about more then free software

* Training opportunity for GC employees
* Helps staff stay up-to-date on new tech
* Attract talent

Note:

___

<!-- .slide: id="dataviz-why-open-formats" data-transition="concave" -->

# Why Open Formats?

> Developing in the open

* Easier to mashup data with other sources
* Enables 3rd party developers to create own data
* Decreate learning curve for using out data

Note:

___

<!-- .slide: id="dataviz-stack" data-transition="concave" -->

# DataViz OS Stack

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li class="list-unstyled"><img src="/img/architecture/openfirst/docker-icon.png" height=200px></img></li>
<li class="list-unstyled"><img src="/img/architecture/openfirst/d3js-icon.png" height=200px></img></li>
</ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li class="list-unstyled"><img src="/img/architecture/openfirst/nodejs-icon.png" height=200px></img></li>
<li class="list-unstyled"><img src="/img/architecture/openfirst/i18next-icon.png" height=200px></img></li>
</ul>
</div>

Note:

___

<!-- .slide: id="dataviz-formats" data-transition="concave" -->

# Open Formats

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li class="list-unstyled"><img src="/img/architecture/openfirst/jsonapi-icon.png" height=200px></img></li>
<li class="list-unstyled"><img src="/img/architecture/openfirst/schema-icon.png" height=200px></img></li>
</ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li class="list-unstyled"><img src="/img/architecture/openfirst/json-ld.png" height=200px></img></li>
<li class="list-unstyled"><img src="/img/architecture/openfirst/iso-icon.png" height=200px></img></li>
</ul>
</div>

Note:

---

<!-- .slide: id="wxt-community" data-background-image="/img/architecture/openfirst/drupal-community.jpg" -->

___

<!-- .slide: id="wxt" data-transition="concave" -->

# Drupal

* Data Modeling
* Configuration Management
* ACL
* Web Services: jsonAPI, GraphQL
* Workspaces

Note:

___

<!-- .slide: id="wxt-d7" data-transition="concave" -->

WxT D7 <!-- .element: class="col-xs-3 col-sm-3 col-md-3 bg-primary" -->

A installation profile which relies on and integrates extensively with the
WxT jQuery Framework.<!-- .element: class="col-xs-9 col-sm-9 col-md-9 text-left" style="padding-left: 1em; padding-bottom: 1em;" -->

* 5+ years operational track record
* 10+ departments leveraging
* Some provinces / municipalities
* A lot of lessons learned

Note:

___

<!-- .slide: id="wxt-d8" data-transition="concave" -->

WxT D8<!-- .element: class="col-xs-3 col-sm-3 col-md-3 bg-primary" -->

A sub-profile of Lightning which relies on and integrates extensively with the
WxT jQuery Framework.<!-- .element: class="col-xs-9 col-sm-9 col-md-9 text-left" style="padding-left: 1em; padding-bottom: 1em;" -->

- Lightweight and extensible
- Supports all WxT themes
- Improved layouts aligned to GoC IA spec
- WxT Bootstrap / Library (standalone)
- Variety of WxT Plugins ported
- Work underway for WET5

Note:

## Lessons learned

Built with lessons learned from Drupal 7 WetKit, in use by several departments,
including the current Open Data portal. One of the biggest decisions was
deciding to leverage Lightning as our base framework. This choice wasn't made
carelessly but 6 months in I can say it has been an incredible time saver,
allowing us to more readily focus on departmental customizations.

## Lightweight and extensible

Following the practice of Lightning WxT tries to keep it scope minimal and
ensure when functionality is added that it can be easily disabled. WxT Extend
is a wrapper module which enables more advanced functionality and gets enabled
during an install callback.

## WxT Themes

All of the various WET-BOEW themes are supported and can be toggled in either
a minifed / non minified mode

## Improved layouts

We integrated with bootstrap layouts which extends from layout discovery
in core and gives us impressibe grid control to support many types of layouts.
We are slowly moving the layouts from the official IA spec from GoC

## WxT Bootstrap / WxT Library

Given in the spirit of modularity WxT Bootstrap theme theme layer can be run
without the weight of a distribution and only requirement is the WxT Library
module due to theme system limitations.

## WxT Plugins ported

A variety of WxT plugins have been ported.

___

<!-- .slide: id="lightning" data-transition="concave" -->

Lightning<!-- .element: class="col-xs-3 col-sm-3 col-md-3 bg-primary" data-fragment-index="1" --> <i class="fa fa-bolt"></i>

Lightning's mission is to enable devs to create great authoring
experiences and empower editorial teams.<!-- .element: class="col-xs-9 col-sm-9 col-md-9 text-left" data-fragment-index="2" style="padding-left: 1em; padding-bottom: 0.25em;" -->

- Minimal opt-in design
- Extensively tested + secured @ [Acquia](http://lightning.acquia.com/)
- Targets several key functional areas:
  * Media
  * Layout
  * Workflow
  * API-First

Note:

Lightning is a top Distribution in Drupal 8 backed by Acquia allowing you to
build experiences quickly using the best of Drupal 8 in a feature rich,
extensively tested, and secure open source distribution. Lightning powers huge
sites such as:

* Princeton
* Tesla
* Pfizer
* ToDo: Update this list

4 key functional areas are targeted:

* Drag and Drop Layouts: Configure page layouts with drag and drop tools. Of note transitioning to core's Layout Builder from Panels / Panelizer.

* Media Management: Embed images, videos, instragram, twitter and more from Drupal or other sources into content and pages.

* Workflows: Configure workflows that keep content moving through review and approval stages, easily. Also features improvements to the native panelizer experience.

* API First: Lightning ships with several modules which, together, quickly set up Drupal to deliver data to decoupled applications via a standardized API. Toolkit for authentication, auth, and delivery of data to API consumers.

* OpenAPI
* JsonAPI
* Simple OAuth

Progressive Enhancements now that React.js is in core is also being added.

* Scheduler

___

<!-- .slide: id="wxt-od" data-transition="concave" -->

Open Data<!-- .element: class="col-xs-3 col-sm-3 col-md-3 bg-primary" -->

A sub-profile of WxT which serves as the front-end user engagement portal for
GoC @ Open Data<!-- .element: class="col-xs-9 col-sm-9 col-md-9 text-left" style="padding-left: 1em; padding-bottom: 1em;" -->

* User Engagement
* Decoupled improvements
* CKAN / Solr integration
* Refined workflows
* Improved search

Note:

Finally this brings us to our Open Data sub-profile of WxT. Importantly this
profile must run in a PostgreSQL backed environment so all modules have been
extensively tested against that. It features a variety of improvements whether
across the data modelling all the way through to the template layer.

___

<!-- .slide: id="wxt-stc" data-transition="concave" -->

Statistics Canada<!-- .element: class="col-xs-3 col-sm-3 col-md-3 bg-primary" -->

A sub-profile of WxT which serves as the front-end user engagement portal for
Statistics Canada<!-- .element: class="col-xs-9 col-sm-9 col-md-9 text-left" style="padding-left: 1em; padding-bottom: 1em;" -->

- New Dissemination Model
- oAuth
- Tailored workflows
- Content Staging / Deployment

Note:

___

<!-- .slide: id="wxt-ask" data-transition="concave" -->

# Need Your Help

* ToDo (Talk w/Nathan)

Note:

---

# Go

<!-- .slide: id="cloudnative-landscape" data-background-size="contain" data-background="#FFFFFF" -->

![Gophers](/img/architecture/openfirst/gophers.png)

___

<!-- .slide: id="golang" data-transition="concave" -->

# Go

* Language of the cloud
* Efficient and easy to learn
* Multi Platform
* Follow the best laid path

Note:

* Incredibly fast and on par with a well written C program and you can write Go much faster
* The static binaries it builds are incredibly easy to deploy. Think scratch container + go app itself
* Incredible amount of freedom but usually only one best practice way of doing some
* Don't need to prove how cool you are by doing pointer arithmetic for no other reason then you can
* Build your programs for many different platforms:
  * Linux, Solaris, Mac OSX
  * Windows
  * BSD's on am64, i686, or ARM
  * Obviously need to make sure your libraries aren't platform specific
* Backend and systems programming so much more accessible thanks to a simple elegant language:
  * Profiling and Tracing tools are great
  * Concurrency is built into go and so easy to work with
  * Go's interfaces can take some time to wrap your brain around

___

<!-- .slide: id="golang-projects" data-transition="concave" -->

# Projects

> We use the following projects quite extensively at Statistics Canada

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li>ACS Engine</li>
<li>ARK</li>
<li>Traefik</li>
<li>Grafana / Prometheus</li>
</ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li>Hugo</li>
<li>Vault</li>
<li>**Docker**</li>
<li>**Kubernetes**</li>
</ul>
</div>

Note:

While not an exhaustive list these are a few of the projects we are actively using and taking into Production.

Just wanted to mention we will go over Docker and Kubernetes later in the presentation so won't mention here.

___

<!-- .slide: id="golang-acs-engine" data-transition="concave" -->

# ACS Engine

> For operators that need complete control and customizability of a Kubernetes cluster.

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li>OS core of ACS/AKS</li>
<li>ARM templates via spec</li>
<li>Immense customization</li>
</ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
<li>Custom extensions</li>
<li>Provided examples</li>
<li>Detailed scenarios</li>
</ul>
</div>

Note:

The Azure Container Service Engine (acs-engine) generates ARM (Azure Resource Manager) templates for Docker enabled clusters on Microsoft Azure.

The input to the tool is a cluster definition.

The cluster definition is very similar to (in many cases the same as) the ARM template syntax used to deploy a Microsoft Azure Container Service cluster.

acs-engine reads a JSON cluster definition and generates a number of files that may be submitted to Azure Resource Manager (ARM). The generated files include:

* apimodel.json: is an expanded version of the cluster definition provided to the generate command. All default or computed values will be expanded during the generate phase
* azuredeploy.json: represents a complete description of all Azure resources required to fulfill the cluster definition from apimodel.json
* azuredeploy.parameters.json: the parameters file holds a series of custom variables which are used in various locations throughout azuredeploy.json
* certificate and access config files: orchestrators like Kubernetes require certificates and additional configuration files (apiserver certificates and kubeconfig)

Normally you can simply run acs-engine deploy to do a one-off cluster, however as we are building lots of clusters we are generating our templates first, and then running the deployment.

This has advantages because we can iterate over a bunch of different cluster declarations.

We can then run them through acs-engine generate to get the definitive template/params for sending to ARM.

## Generation of ARM Templates

```sh
acs-engine generate --api-model=k8s.default.json
```

There are a variety of examples that acs-engine provides to get you started with the following:

## Examples

* Clear Containers
* OpenShift
* Hybrid Windows
* ACI Connector
* Key vault
* GPU
* Managed Identity
* Service Mesh (istio)
* Encryption by Default
* Private Clusters

Additionally ACS Engine support extensions that can provide additional logic to your cluster when deploying. We actually made and submitted the Choco extension to acs-engine.

## Custom Extensions

* Choco: This extension installs packages passed as parameters via via Chocolatey package manager.
* Register DNS: Registers the Node the extension is applied against into the Azure active directory domain via nsupdate.
* Virtualbox: Extension which provisions a node with virtualbox drivers which can be leveraged via CI by Jenkins.

The following represents a list of some common scenarios that we have been using internally at Statistics Canada

## Scenarios

### Custom DNS:

When there are custom dns servers k8s needs the custom dns to handle the routing and as a result /etc/resolv.conf isn't correct.

https://github.com/Azure/acs-engine/issues/1603

### Custom VNET

https://github.com/Azure/acs-engine/blob/master/examples/vnet/kubernetesvnet.json

Very important to specify the vnetSubnetId and firstConsecutiveStaticIp.

### Linux / Windows node pool

Adding a node pool

* Add (or copy) an entry in the agentPoolProfiles section in the _output/<clustername>/apimodel.json file

Removing a node pool

* Delete the related entry from agentPoolProfiles section in the _output/<clustername>/apimodel.json file
* Drain nodes from inside Kubernetes
* Generate and deploy
* Delete VM's and related resources (disk, NIC, availability set) from Azure portal

Resizing Virtual Machines in a node pool

* Modify the vmSize in the agentPoolProfiles section
* Generate and deploy

Resizing a Node Pool

* Should use acs-engine scale see in a few slides the implementation

YouTube

* https://www.youtube.com/watch?v=VuPmL25_Cls

___

<!-- .slide: id="golang-acs-engine-demo" data-transition="concave" -->

# ACS Engine

> Demo: Lets quickly look at how acs-engine is leverage for deploying clusters

* Generate ARM templates from Cluster Definition
* Execute the newly generated ARM templates
* Scale an agent pool inside cluster
* Delete the entire cluster

Note:

## Create Cluster

Deployment of the cluster is relatively straight forward and can be executed again once changes are made to the api model and then regenerated.

* Execute the generated artifacts
* Always use **azuredeploy.json** file
* Check the activity log for status
* Consider leveraging Azure Key Vault for Certs

```sh
az group deployment create --name "acs-default" \
                          --resource-group "acs-default" \
                          --template-file "./_output/k8s-acs-default/azuredeploy.json" \
                          --parameters "./_output/k8s-acs-default/azuredeploy.parameters.json"
```

## Scale Cluster

After a cluster has been deployed using acs engine the cluster can be interacted further by using the scale command.

The scale command can add more nodes to an existing node pool or remove them.

Nodes will always be added or removed from the end of the agent pool. Nodes will be cordoned and drained before deletion.

```sh
acs-engine scale --subscription-id <subscription-id> \
                 --resource-group acs-default \
                 --location eastus \
                 --deployment-dir _output/k8s-acs-default \
                 --new-node-count 3 \
                 --node-pool linuxpool1 \
                 --master-FQDN <fqdn>
```

___

<!-- .slide: id="golang-ark" data-transition="concave" -->

# ARK

> Demo: Lets quickly look at how ARK can help us with disaster recovery

* Manages disaster recovery
* Backups of cluster and restore
* Copy cluster resources across clouds
* Replicate your production environments

Note:

Heptio Ark is a utility for managing disaster recovery, specifically for your Kubernetes cluster resources and persistent volumes.

Ark gives you tools to back up and restore your Kubernetes cluster resources and persistent volumes. Ark lets you:

* Take backups of your cluster and restore in case of loss.
* Copy cluster resources across cloud providers. NOTE: Cloud volume migrations are not yet supported.
* Replicate your production environment for development and testing environments.

Ark consists of:

* A server that runs on your cluster
* A command-line client that runs locally

YouTube

* https://www.youtube.com/watch?v=sHLRedoRSp0

# Backup Application

```sh
ark backup create jenkins --selector app=jenkins-jenkins \
                          --snapshot-volumes
```

# Backup Cluster

```sh
ark backup create cluster --exclude-namespaces=kube-system \
                          --snapshot-volumes
```

# Scheduled Backup

```sh
ark schedule create gitlab --selector app=gitlab-gitlab \
                           --snapshot-volumes \
                           --schedule "0 7 * * *"
```

___

<!-- .slide: id="golang-grafana" data-transition="concave" -->

# Grafana / Prometheus

<div class="col-xs-12 col-sm-12 col-md-12">
<ul class="list-unstyled">
<iframe src="https://grafana.k8s.cloud.statcan.ca/d-solo/a72yEIoik/k8s?orgId=1&panelId=13&from=1537965871160&to=1537976671160&var-node=172.20.57.4" width="900" height="250" frameborder="0"></iframe>
</ul>
</div>

<div class="col-xs-12 col-sm-12 col-md-12">
<ul class="list-unstyled">
<iframe src="https://grafana.k8s.cloud.statcan.ca/d-solo/a72yEIoik/k8s?orgId=1&from=1537803639069&to=1537976439069&panelId=14&var-node=172.20.57.4" width="900" height="250" frameborder="0"></iframe>
</ul>
</div>

Note:

> Demo: [grafana.k8s.cloud.statcan.ca](http://grafana.k8s.cloud.statcan.ca)

As a time series database, prometheus is often used in the world of monitoring systems in combination with grafana, which is at the very basic level a visualization tool for time series data.

I will show you an example of what our full dashboard looks like.

# Important Points

* Brought up in K8S
* Linked with Active Directory
* Assignment to Different Groups
* Dashboard can become embeddable
* Custom Alerts based on metrics you define (slack)

___

<!-- .slide: id="golang-traefik" data-transition="concave" data-background="#FFFFFF" -->

# Traefik

![Traefik](/img/architecture/openfirst/traefik.svg)

Note:

Træfik is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy.

Træfik integrates with your existing infrastructure components (Docker, Swarm mode, Kubernetes, Marathon, Consul, Etcd, Rancher, Amazon ECS, ...) and configures itself automatically and dynamically.

Pointing Træfik at your orchestrator should be the only configuration step you need.

## Overview

Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul). Now you want users to access these microservices, and you need a reverse proxy.

Traditional reverse-proxies require that you configure each route that will connect paths and subdomains to each microservice. In an environment where you add, remove, kill, upgrade, or scale your services many times a day, the task of keeping the routes up to date becomes tedious.

This is when Træfik can help you!

Træfik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part.

# Features

* Continuously updates its configuration (No restarts!)
* Supports multiple load balancing algorithms
* Provides HTTPS to your microservices by leveraging Let's Encrypt (wildcard certificates support)
* Circuit breakers, retry
* High Availability with cluster mode (beta)
* See the magic through its clean web UI
* Websocket, HTTP/2, GRPC ready
* Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB)
* Keeps access logs (JSON, CLF)
* Fast
* Exposes a Rest API
* Packaged as a single binary file (go) and available as a tiny official docker image

# Supported Providers

* Docker / Swarm mode
* Kubernetes
* Mesos / Marathon
* Rancher (API, Metadata)
* Azure Service Fabric
* Consul Catalog
* Consul / Etcd / Zookeeper / BoltDB
* Eureka
* Amazon ECS
* Amazon DynamoDB
* File
* Rest

___

<!-- .slide: id="golang-traefik" data-transition="concave" data-background="#FFFFFF" -->

# Traefik

> Demo: Lets take a look at a couple of our Traefik environments

* [traefik.k8s.cloud.statcan.ca](http://traefik.k8s.cloud.statcan.ca)
* [traefik.inno.cloud.statcan.ca](http://traefik.inno.cloud.statcan.ca)
* [traefik.devtest.cloud.statcan.ca](http://traefik.devtest.cloud.statcan.ca)

Note:

We use Traefik extensively for our Kubernetes clusters.

* Lets Encrypt for all of our Ingresses in Management Cluster
* Ability for automatic ingress in GitLab CI Pipelines
* CIDR blocking at the Traefik level for JupyterHub
* Passing of special headers for applications that need them
* Working on end to end encryption for all the backend services
* ToDo: Ask Zach for more information

___

<!-- .slide: id="golang-vault" data-transition="concave" -->

# Vault

![Vault](/img/architecture/openfirst/vault-auth-workflow.svg)

Note:

Vault: A tool for secrets management, encryption as a service, and privileged access management.

Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.

A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.

The key features of Vault are:

Secure Secret Storage: Arbitrary key/value secrets can be stored in Vault. Vault encrypts these secrets prior to writing them to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Vault can write to disk, Consul, and more.

Dynamic Secrets: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.

Data Encryption: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as SQL without having to design their own encryption methods.

Leasing and Renewal: All secrets in Vault have a lease associated with it. At the end of the lease, Vault will automatically revoke that secret. Clients are able to renew leases via built-in renew APIs.

Revocation: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.

* ToDo: Ask Zach for more information

___

<!-- .slide: id="golang-hugo" data-transition="concave" -->

# Hugo

* Static site generator 30,000 stars
* WxT support @ wet-boew/wet-boew-hugo
* Used for documentation sites at STC
* GitLab CI generates / deploys to GitLab Pages

Note:

> Demo: [wet-boew/wet-boew-hugo](http://github.com/wet-boew/wet-boew-hugo)

Also will quickly demo and do a brief tour of the govcloud Hugo site.

* Markdown
* Concept of Content Types
* Fully supports i18n
* Supports shortcodes (gh-starred, img, youtube)
* Incredibly fast
* Tons of other features

---

<!-- .slide: id="cloudnative-landscape" data-background-size="contain" data-background-image="/img/architecture/openfirst/cncf-landscape.png" -->

___

<!-- .slide: id="cloudnative-infra" data-transition="concave" -->

# Cloud Native

> Cloud native infrastructure is infrastructure that is:

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
  <li>Hidden behind useful abstractions</li>
  <li>Controlled by API's</li>
  <li>Managed by software</li>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
<ul class="list-unstyled">
  <li>Purpose is to run application lifecycle</li>
  <li>Exposes own API</li>
  <li>Move up the stack</li>
</div>

Note:

Cloud native infrastructure is infrastructure that is hidden behind useful abstractions, controlled by APIs, managed by software, and has the purpose of running applications. Running infrastructure with these traits gives rise to a new pattern for managing that infrastructure in a scalable, efficient way.

Abstractions are useful when they successfully hide complexity for their consumer. They can enable more complex uses of the technology, but they also limit how the technology is used. They apply to low-level technology, such as how TCP abstracts IP, or higher levels, such as how VMs abstract physical servers. Abstractions should always allow the consumer to “move up the stack” and not reimplement the lower layers.

Cloud native infrastructure needs to abstract the underlying IaaS offerings to provide its own abstractions. The new layer is responsible for controlling the IaaS below it as well as exposing its own APIs to be controlled by a consumer.

Infrastructure that is managed by software is a key differentiator in the cloud. Software-controlled infrastructure enables infrastructure to scale, and it also plays a role in resiliency, provisioning, and maintainability. The software needs to be aware of the infrastructure’s abstractions and know how to take an abstract resource and implement it in consumable IaaS components accordingly.

So at its most fundamental level a cloud native application is engineered to run on a cloud platform and is designed for:

* Resiliency: Embraces failures instead of trying to prevent them; it takes advantage of the dynamic nature of running on a cloud platform
* Agility: Allows for fast deployments and quick iterations
* Operability: Adds control of application life cycles from inside the application instead of relying on external processes and monitors
* Observability: Provides information to answer questions about application state

___

<!-- .slide: id="cloudnative" data-transition="concave" -->

# Cloud Native

> The following doesn't automatically mean your Cloud Native.

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Infra on public cloud</li>
    <li>Apps in containers</li>
	<li>Container orchestrator</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Microservices</li>
    <li>Infra as Code</li>
    <li>Config management</li>
  </ul>
</div>

Note:

Cloud native infrastructure is not only running infrastructure on a public cloud. Just because you rent server time from someone else does not make your infrastructure cloud native. The processes to manage IaaS are often no different than running a physical data center, and many companies that have migrated existing infrastructure to the cloud have failed to reap the rewards.

Cloud native is not only about running applications in containers. When Netflix pioneered cloud native infrastructure, almost all its applications were deployed with virtualmachine images, not containers. The way you package your applications does not mean you will have the scalability and benefits of autonomous systems. Even if your applications are automatically built and deployed with a continuous integration and continuous delivery pipeline, it does not mean you are benefiting from infrastructure that can complement API-driven deployments.

It also doesn’t mean you only run a container orchestrator (e.g., Kubernetes and Mesos). Container orchestrators provide many platform features needed in cloud native infrastructure, but not using the features as intended means your applications aren't dynamically scheduled to run on a set of servers. This is a very good first step, but there is still work to be done.

Cloud native is not about microservices or infrastructure as code. Microservices enable faster development cycles on smaller distinct functions, but monolithic applications can have the same features that enable them to be managed effectively by software and can also benefit from cloud native infrastructure. Infrastructure as code defines and automates your infrastructure in machine-parsible language or domain-specific language (DSL). Traditional tools to apply code to infrastructure include configuration management tools (e.g., Chef and Puppet). These tools help greatly in automating tasks and providing consistency, but they fall short in providing the necessary abstractions to describe infrastructure beyond a single server. Configuration management tools automate one server at a time and depend on humans to tie together the functionality provided by the servers. This positions humans as a potential bottleneck for infrastructure scale. These tools also don’t automate the extra parts of cloud infrastructure (e.g., storage and network that are needed to make a complete system.

___

<!-- .slide: id="cloudnative-impl" data-transition="concave" -->

# Traits

> Acquire the traits of Resiliency, Agility, Operability, Observability through:

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Microservices</li>
    <li>Health reporting</li>
    <li>Telemetry data</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Resiliency</li>
    <li>Declarative not Reactive</li>
  </ul>
</div>

Note:

Cloud native applications acquire the traits of (Resiliency, Agility, Operability, Observability) through various methods.

The following represents a common way to implement the desired characteristics:

> Reminder: It can often depend on where your applications run and the processes and culture of the business.

* Microservices: Separate clearly defined functionality into smaller services and let each service independently iterate
* Health reporting: To increase the operability of cloud native applications, applications should expose a health check, liveness, and readyness probes
* Telemetry data: Teleetry data can overlap with health reporting, but serve different purposes. Health reporting informs us of application life cycle, while telemetry data informs us of application business objectives.
  * How many requests per minute does the application receive?
  * Are there any errors?
  * What is the application latency?
  * How long does it take to place an order?
* Resiliency: Become resilient to failure and embrace it as a function of design.
* Declarative: Communication through the network through REST and/or Remote Procedure Calls (RPC)

___

<!-- .slide: id="cloudnative-cncf" data-transition="concave" -->

# Cloud Native: CNCF

> Orchestration of containers as part of a microservices architecture.

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Containerization</li>
    <li>Dynamically orchestrated</li>
    <li>Microservices oriented</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Optimized resource utilization</li>
    <li>Distributed computing</li>
    <li>41,145 Contributors</li>
  </ul>
</div>

Note:

The Cloud Native Computing Foundation is an open source software foundation dedicated to making cloud native computing universal and sustainable.

Cloud native computing uses an open source software stack to deploy applications as microservices, packaging each part into its own container, and dynamically orchestrating those containers to optimize resource utilization.

The CNCF serves as the vendor-neutral home for many of the fastest-growing projects on GitHub, including Kubernetes, Prometheus and Envoy, fostering collaboration between the industry’s top developers, end users, and vendors.

___

<!-- .slide: id="cloudnative-cncf-kubernetes" data-transition="concave" -->

# CNCF: Kubernetes

![Kubernetes](/img/architecture/openfirst/cncf-kubernetes.png)

Note:

___

<!-- .slide: id="cloudnative-cncf-prometheus" data-transition="concave" -->

# CNCF: Prometheus

![Prometheus](/img/architecture/openfirst/cncf-prometheus.svg)

Note:

___

<!-- .slide: id="cloudnative-cncf-helm" data-transition="concave" -->

# CNCF: Helm

![Helm](/img/architecture/openfirst/cncf-helm.png)

Note:

___

<!-- .slide: id="cloudnative-cncf-grpc" data-transition="concave" -->

# CNCF: gRPC

![gRPC](/img/architecture/openfirst/cncf-grpc.png)

Note:

___

<!-- .slide: id="cloudnative-cncf-cni" data-transition="concave" -->

# CNCF: CNI

![CNI](/img/architecture/openfirst/cncf-cni2.png)

Note:

___

<!-- .slide: id="cloudnative-cncf-meetups" data-transition="concave" -->

# GoC Meetups

* GoC Cloud Native Working Group
* 80+ Members
* CDS / Statistics Canada
* Usually 2 x 45 minute sessions

Note:

___

<!-- .slide: id="cloudnative-cncf-meetups-past" data-transition="concave" -->

# GoC Past Meetups

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Container Architecture</li>
    <li>Kubernetes Orchestrator</li>
    <li>Azure ACS/AKS and ACS-Engine</li>
    <li>Terraform</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>JupyterHub</li>
    <li>gRPC/Protobuffers</li>
    <li>Artifactory / XRay</li>
  </ul>
</div>

Note:

___

<!-- .slide: id="cloudnative-cncf-meetups-future" data-transition="concave" -->

# GoC Future Meetups

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>GCTools</li>
    <li>OpenShift</li>
    <li>Traefik</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Windows Containers</li>
    <li>Rancher Cattle</li>
    <li>Terraform with GitLab CI</li>
  </ul>
</div>

Note:

* GCTools is willing to do a demo and show off their CI/CD process
* OpenShift demo by both CDS and RedHat
* Traefik presentation given by one of the maintainers who met a K8S meetup
* Terraform with GitLab CI by Andriy Drozdyuk
* Bernard Maltais (PSPC) showcasing Rancher Cattle
* Mark Tessier / William Hearn discussing Windows containers

---

<!-- .slide: id="containers-docker-nyan" data-background-size="contain" data-background="/img/architecture/openfirst/nyan_docker.gif" -->

___

<!-- .slide: id="containers-overview" data-transition="concave" -->

# Containerization

> Agile, lightweight building blocks to build, ship, and run any application, across any infrastructure

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Platform independence</li>
    <li>Resource efficiency and density</li>
    <li>Effective isolation and resource sharing</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Immense and smooth scaling</li>
    <li>Operational simplicity</li>
    <li>Developer productivity</li>
    <li>Speed</li>
  </ul>
</div>

Note:

Everyone that learns about containers and their server immutability concept invariably loves them, because of the power they give, both on the development and in the deployment sides.

**Platform independence: Build it once, run it anywhere**

A major benefit of containers is their portability. In particular containers help to facilitate a cloud native approach via a microservices architectural design pattern.

A container wraps up an application with everything it needs to run, like configuration files and dependencies. This enables you to easily and reliably run applications on different environments such as your local desktop, physical servers virtual servers, testing, staging, production environments and public or private clouds.

This portability grants organisations a great amount of flexibility, speeds up the development process and makes it easier to switch to another cloud environment or provider, if need be.

**Resource efficiency and density**

Since containers do not require a separate operating system, they use up less resources. While a VM often measures several gigabytes in size, a container usually measures only a few dozen megabytes, making it possible to run many more containers than VMs on a single server.

Since containers have a higher utilisation level with regard to the underlying hardware, you require less hardware, resulting in a reduction of bare metal costs as well as datacentre costs.

**Effective isolation and resource sharing**

Although containers run on the same server and use the same resources, they do not interact with each other. If one application crashes, other containers with the same application will keep running flawlessly and won’t experience any technical problems. This isolation also decreases security risks: If one application should be hacked or breached by malware, any resulting negative effects won’t spread to the other running containers.

**Speed: Start, create, replicate or destroy containers in seconds**

As mentioned before, containers are lightweight and start in less than a second since they do not require an operating system boot. Creating, replicating or destroying containers is also just a matter of seconds, thus greatly speeding up the development process, the time to market and the operational speed. Releasing new software or versions has never been so easy and quick. But the increased speed also offers great opportunities for improving customer experience, since it enables organisations and developers to act quickly, for example when it comes to fixing bugs or adding new features.

**Immense and smooth scaling**

A major benefit of containers is that they offer the possibility of horizontal scaling, meaning you add more identical containers within a cluster to scale out. With smart scaling, where you only run the containers needed in real time, you can reduce your resource costs drastically and accelerate your return on investment. Container technology and horizontal scaling has been used by major vendors like Google and Twitter for years now.

**Operational simplicity**

Contrary to traditional virtualisation, where each VM has its own OS, containers execute application processes in isolation from the underlying host OS. This means that your host OS doesn’t need specific software to run applications, which makes it simpler to manage your host system and quickly apply updates and security patches.

**Improved developer productivity and development pipeline**

A container-based infrastructure offers many advantages, promoting an effective development pipeline. Let’s start with one of the most well-known benefits. As mentioned before, containers ensure that applications run and work as designed locally. This elimination of environmental inconsistencies makes testing and debugging less complicated and less time-consuming since there are fewer differences between running your application on your workstation, test server or in production environment. The same goes for updating your applications: you simply modify the configuration file, create new containers and destroy the old ones, a process which can be executed in seconds. In addition to these well-known benefits, container tools like Docker offer many other advantages. One of these is version control, making it possible for you to roll-out or roll-back with zero downtime. The possibility to use a remote repository is also a major benefit when working in a project-team, since it enables you to share your container with others.

## Data Points

* 71% of Fortune 100 companies are running containers

___

<!-- .slide: id="containers-docker" data-transition="concave" -->

# Docker

* Docker for Mac
* Docker for Windows
* Helpful Tips

Note:

___

<!-- .slide: id="containers-vscode" data-transition="concave" -->

# VSCode

* Dockerfile code completion
* Docker Compose support
* Generation of Docker files
* Docker Hub
* Linting

Note:

https://code.visualstudio.com/docs/azure/docker

___

<!-- .slide: id="windows" data-transition="concave" -->

# Windows

![windows](/img/architecture/openfirst/docker-windows-server.jpg)

Note:

Microsoft is doing a lot of great things in the Container space and honestly this is coming from a Linux developer.

* VSCode works on Windows
* Visual Studio
  * Integrated Docker tooling and full application lifecycle
  * Multi-container Support via Docker-Compose
  * Support orchestrators like Kubernetes
* Porting MSSQL Server to Linux

Whitepaper: https://www.microsoft.com/en-ca/cloud-platform/containers

___

<!-- .slide: id="windows-server" data-transition="concave" -->

# Windows Server

> Windows Server Containers native to Windows Server 2016

Docker enables full ecosystem of tools:

* PowerShell
* CLI
* Docker Data Center
* Hyper-V Isolation
* **New**: Active Directory (MSI)

Note:

___

<!-- .slide: id="windows-server-startup" data-transition="concave" -->

# Windows Server

> Compare the startup time performance of NodeJS

| Nano Server   |                         | Windows Server Core  |
| ------------- | ----------------------- | -------------------- |
| < 600 ms      | Windows Server Conainer |  1s                  |
| 1.75s        | Hyper-V Isolation       |  3.3s                 |
| 3 s           | Virtual Machine         |  5-60+               |

Note:

___

<!-- .slide: id="windows-server-dockerfile" data-transition="concave" -->

# Windows Dockerfile

> Demo: Lets take a look at a valid Dockerfile

* Artifactory
* Nuget
* .Net Build / MSPublish
* Multi-Stage Build

Note:

Let's take a look at the following Dockerfile.

## Build Container

Essentially we are running an official image used for running .NET Framework applications on Windows Server Core

* Pull from microsoft/dotnet-framework using the 4.7.2-sdk-windowsservercore-1803 tag and giving the `FROM` a `build` name declaration
* We are doing something interesting in that we prefix our artifactory instance's docker repo as a proxy through
* Note the 1803 tag as opposed to 1709 in the next slide I will tag about this important detail more
* We then switch to the `/app` directory conveniently placed by the base image
* We now can copy all of our current directory into the container (excluding .dockerignore)
* The first step should be to always restore from Nuget your dependant libraries (Artifactory)
* The next step is to then run `dotnet msbuild` passing in your respective configuration parameters

## Multi Stage Build

What you might notice now is that we are now calling a completely different container which is used for hosting WCF services in Windows Server Core

* Pull from microsoft/wcf using the 4.7.2-sdk-windowsservercore-1803 tag and giving the `FROM` a `runtime` name declaration
* We then just make ourselves a new directory and set it as our default
* Now for the fun step of calling what we build in our earlier build container and just copying the newly built artifact itself into the new container
* Finally we leverage powershell to quickly launch us a new IIS Site name SecurityService

---

<!-- .slide: id="k8s-magic" data-background-size="contain" data-background="https://media.giphy.com/media/12NUbkX6p4xOO4/giphy.gif" -->

___

<!-- .slide: id="k8s" data-transition="concave" -->

# Kubernetes

> Kubernetes is the world’s most popular container-orchestration platform and the first CNCF project.

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Managed complexity</li>
    <li>Open Service Broker</li>
    <li>Multi cloud</li>
    <li>Self-healing</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Google backed</li>
    <li>Vibrant community</li>
    <li>Big name supporters</li>
    <li>No vendor lock-in</li>
  </ul>
</div>

Note:

Kubernetes helps users build, scale and manage modern applications and their dynamic lifecycles.

First developed at Google, Kubernetes now counts 5000+ contributors and is used by some of the world’s most-innovative companies, across a wide range of industries.

The cluster scheduler capability lets developers build cloud native applications while focusing on code rather than ops.

Kubernetes future-proofs application development and infrastructure management on-premises or in the cloud, without vendor or cloud-provider lock-in.

## Background

A container orchestrator is a software that is able to orchestrate and organize containers across any number of physical or virtual nodes. The potential of this is enormous, as it greatly simplifies the deployment of the infrastructure (each node only has Docker installed) and its operation (as all servers are exactly equal). The container orchestrator takes in account things as failing nodes, adding more nodes to the cluster or removing nodes from the cluster by moving the containers from one node to another to keep them available at all times.

While containers + orchestrators technology not only resolves a lot of problems related with infrastructure management, it also resolves a lot of problems regarding deploying software in the infrastructure, as the software, its dependencies and runtime are always deployed at the same time, minimizing the errors commonly associated to deployments in non-immutable environments.

Kubernetes has won the orchestrator wars, hands down and as of 2018 now takes center stage. This is proved by every single cloud vendor integrating with it and providing their own managed service. Additionally by most PAAS's offering first class support for it. (Pivotal, OpenShift, Tectonic)

**Managed complexity**: Automation of the deployment, scaling, and operation of application containers in a clustered environment via primitives

**Vendor Lock-in**: Essentially every major cloud provider (public, private, hybrid) support Kubernetes

**Multi-Cloud**: Ideal for managing multi-cloud environments / workloads

**Self-healing**: Auto-placement, auto-restart, auto-replication, auto-scaling

**Google Backed**: Originally built by Google leveraging a decade of experience running containers at scale

**Vibrant Community**: One of the fastest moving projects in open source history, 2nd largest. Additionally over 30,000 users on slack many google engineers.

**Big Name Supporters**: Google, Microsoft, AWS, IBM, RedHat, Oracle, VMWare, Intel, Pivotal etc

**Flexibility**: Simplicity of a PaaS with the flexibility of IaaS

**Powerful Primitives**:

* Pod
* Service
* Volume
* Namespace
* ReplicaSet
* Deployment
* StatefulSet
* DaemonSet
* Job

> Interesting data points

* 54% of Fortune 100 companies are running Kubernetes
* Housed within a large, neutral open source foundation, the Cloud Native Computing Foundation
* CNCF consists of enterprise companies such as Microsoft, Google, AWS, SAP, Oracle, Pivotal, etc
* Kubernetes has won the orchestration wars and is recognized as the de facto standard for container orchestration
* Gartner: By 2020, more than 50% of global enterprises will be running containerized applications in production.
* With that, Kubernetes has emerged as the leading orchestration method in the market with a 71% adoption rate.
* Second largest repository on GitHub only behind Linux
* More then 2300 contributors
* Used by some of the worlds most innovative companies
* Over 75,000 members on Slack across different SIG's

___

<!-- .slide: id="k8s-gov" data-transition="concave" -->

# Government

> Kubernetes aligns with governments strategic direction

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>SSC Cloud Platform</li>
    <li>CSE / CSIS</li>
    <li>CDS / TBS</li>
	<li>STC</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>OpenShift</li>
    <li>Pivotal</li>
    <li>IBM</li>
    <li>Oracle</li>
  </ul>
</div>

Note:

SSC now has its own Cloud Platform (OpenShift). RedHat's corporate offering of Kubernetes

A few other departments have either procured OpenShift / Pivotal:

* CSEC / CSIS: Using OpenShift for a few years
* CDS: Have a year license of OpenShift
* ESDC / ISED: Building apps and onboarding on OpenShift
* TBS: Evaluating between OpenShift / Pivotal
* STC: Evaluating between OpenShift / Pivotal / AKS etc

> Can send full list of Departments as is impressive the agreement on Kubernetes

___

<!-- .slide: id="chart-overview" data-transition="concave" -->

# Charts

![Overview](/img/helm/chart-illustration.png)

Note:

ToDo

___

<!-- .slide: id="chart-arch" data-transition="concave" -->

# Architecture

![Architecture](/img/helm/chart-architecture.png)

Note:

ToDo

___

<!-- .slide: id="chart-gitlab" data-transition="concave" -->

# Jenkins

![jenkins](/img/architecture/openfirst/jenkinsx.svg)

Note:

* Plugin Architecture
* Plugins with Artifactory
* Kubernetes Clusters and Innovation / DevTest
* YETI (Building and Deploy in a Kubernetes Cluster, DoTNet Application running on Linux frontend, and VM backend for * Databases (90% of our workflow)
* Application itself is build with container and Kubernetes deploy
* All of our infrastructure is done via Jenkins + Kubernetes

___

<!-- .slide: id="chart-gitlab" data-transition="concave" -->

# GitLab

![GitLab](/img/architecture/openfirst/gitlab-workflow.png)

Note:

We use GitLab to host our source code as well as GitLab CI to perform builds and deployment to Kubernetes.

Of course Jenkins can do this to but we have found the polish and workflow in GitLab to be quite exceptional for K8S.

This is likely because the same people who help to build and steer Kubernetes development also use GitLab itself.

___

<!-- .slide: id="chart-gitlab-overview" data-transition="concave" -->

# GitLab

> Demo: Lets show of the key benefits GitLab provides us

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>GitLab running in K8S</li>
    <li>CI runners in separate cluster</li>
    <li>Multiple backups via ARK / CronJob</li>
    <li>9 months operational</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Highest in Gartner</li>
    <li>Fully cloud native</li>
    <li>Improved build/test workflow</li>
  </ul>
</div>

Note:

There are a few key important points I would like to talk about in order to show the value GitLab brings to us:

* Running in Kubernetes without issue for 9+ months
* CI runners run in a separate cluster so as to not affect production (demo)
* ARK is leveraged to perform daily PVC backups (demo)
* Updated GitLab over 5 releases without issue simply by bumping container version
* All of our configuration is housed in the Helm chart
  * GitLab pages is enabled with some teams using Hugo to generate static site documentation
  * Prometheus monitoring is enabled so can see health of GitLab as well as CI builds
  * Email is set to use SendGrid
  * We have both LDAP and Azure Oauth authentication to reduce accounts
* Full CI/CD pipeline across a few projects
  * Drupal @ ADSD
  * .NET @ ADSD
  * Python / Pachyderm @ ADD
  * NodeJS @ Digital Innovation

___

<!-- .slide: id="chart-artifactory" data-transition="concave" -->

## jFrog Artifactory

<div class="stretch">
  <iframe height="100%" width="100%" src="https://www.youtube.com/embed/CypEkbB-JRU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

___

<!-- .slide: id="chart-xray" data-transition="concave" -->

## jFrog X-Ray

<div class="stretch">
  <iframe height="100%" width="100%" src="https://www.youtube.com/embed/lghfzM9R1i0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

___

<!-- .slide: id="chart-octopus" data-transition="concave" -->

## Octopus

___

<!-- .slide: id="chart-datasci" data-transition="concave" -->

# Data Science

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Blockchain</li>
    <li>Hadoop / HDFS</li>
    <li>JupyterHub</li>
    <li>Kylo</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Nifi</li>
    <li>Pachyderm</li>
    <li>Spark</li>
    <li>SAS 4 Containers</li>
  </ul>
</div>

Note:

All cloud native apps vetted and extended from official sources.

___

<!-- .slide: id="chart-drupal" data-transition="concave" -->

# Drupal 7/8

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>gccode -> cloud.statcan</li>
    <li>Microservice approach</li>
    <li>Generation of artifacts</li>
    <li>Every Drupal site with full CI/CD</li>
  </ul>
</div>

<div class="col-xs-6 col-sm-6 col-md-6">
  <ul class="list-unstyled">
    <li>Improved Architecture</li>
    <li>Autoscale / Elastic</li>
    <li>Stateless / Stateful</li>
    <li>Notifications / Metrics</li>
  </ul>
</div>

Note:

* All 5 groups and 188 projects moved to STC GitLab
* All Drupal 7/8 sites are now Containerized / MicroServiced across CI / CD
* As Containers are Stateless, Stateful data problem has been solved elegantly through Azure Storage
* Autoscale both vertically and horizontally across all services via replicasets on demand

---

<!-- .slide: id="serverless-challenger" data-background-size="contain" data-background="https://media.giphy.com/media/bGd3K98aIx104/giphy.gif" -->

___

<!-- .slide: id="serverless" data-transition="concave" -->

# Serverless

* FaaS
* Right tool for the right job
* Cloud Comparisons
* KNative
* Kubernetes Universal Control Plane

Note:
